import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
from scipy.stats import norm, skew, jarque_bera, chi2
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm 

# --- Configuraci√≥n de la P√°gina y Estilos ---
st.set_page_config(
    page_title="VaR: Presentaci√≥n y Backtesting",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Constantes y Par√°metros ---
COMPANIES = ['BOGOTA.CL', 'PFDAVVNDA.CL', 'PFCIBEST.CL', 'JPM', 'BML-PL', 'WFC']
START_DATE = '2020-01-02'
END_DATE = '2023-02-08'
COLOMBIAN_TICKERS = ['BOGOTA.CL', 'PFDAVVNDA.CL', 'PFCIBEST.CL']
NEW_COLUMN_NAMES = {
    'BOGOTA.CL': 'Banco Bogot√°',
    'PFDAVVNDA.CL': 'Davivienda',
    'PFCIBEST.CL': 'Bancolombia',
    'JPM': 'JPMorgan',
    'BML-PL': 'Bank of America',
    'WFC': 'Wells Fargo'
}
NUM_SIMULATIONS = 1000

# --- Funciones de Data Wrangling y Caching ---

@st.cache_data
def load_and_prepare_data(companies, start_date, end_date):
    """Carga los datos de Yahoo Finance y realiza la conversi√≥n a USD."""
    
    data = yf.download(companies + ['COP=X'], start=start_date, end=end_date)['Close']
    
    if data.empty:
        # st.error("Error al cargar los datos. Verifique los tickers y el rango de fechas.")
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

    data.rename(columns={'COP=X': 'COP_USD'}, inplace=True)
    aligned_data = data.dropna(subset=['COP_USD'])
    combined_usd_df = aligned_data.copy()
    
    for ticker in COLOMBIAN_TICKERS:
        if ticker in combined_usd_df.columns:
            combined_usd_df[ticker] = combined_usd_df[ticker] / combined_usd_df['COP_USD']
    
    combined_usd_df.drop(columns=['COP=X', 'COP_USD'], errors='ignore', inplace=True)
    combined_usd_df.rename(columns=NEW_COLUMN_NAMES, inplace=True)
    
    daily_returns_df = combined_usd_df.pct_change().dropna()
    
    return combined_usd_df, daily_returns_df

@st.cache_data
def calculate_descriptive_statistics(df_prices, df_returns):
    """Calcula estad√≠sticas descriptivas y la prueba de normalidad (Jarque-Bera)."""
    
    stats_list = []
    for col in df_prices.columns:
        returns = df_returns[col].dropna()
        jb_statistic, jb_pvalue = jarque_bera(returns)
        skewness_r = skew(returns)
        
        stats_list.append({
            'Activo': col,
            'M√≠nimo (USD)': f'{df_prices[col].min():.2f}',
            'M√°ximo (USD)': f'{df_prices[col].max():.2f}',
            'Media (USD)': f'{df_prices[col].mean():.2f}',
            'Volatilidad (Std. Dev.)': f'{returns.std():.4f}',
            'Asimetr√≠a': f'{skewness_r:.4f}',
            'Kurtosis (Exceso)': f'{returns.kurtosis():.4f}',
            'JB p-valor': f'{jb_pvalue:.4f}',
            'Normalidad Rechazada (a=0.05)': 'S√≠' if jb_pvalue < 0.05 else 'No'
        })
        
    return pd.DataFrame(stats_list).set_index('Activo')

# --- Funciones de C√°lculo del VaR ---

def calculate_var(df_returns, confidence_level, num_simulations):
    """Calcula el VaR Delta-Normal, Hist√≥rico y Monte Carlo."""
    
    alpha = 1 - confidence_level
    var_results = {}
    
    for asset in df_returns.columns:
        returns = df_returns[asset].dropna()
        
        # 1. Delta-Normal VaR
        mean_return = returns.mean()
        std_dev_return = returns.std()
        z_score = norm.ppf(alpha)
        delta_normal_var_return = -(mean_return + z_score * std_dev_return)
        
        # 2. Historical Simulation VaR
        historical_var_return = -returns.quantile(alpha)
        
        # 3. Monte Carlo Simulation VaR (Asumiendo GBM)
        np.random.seed(42)
        simulated_returns = np.random.normal(mean_return, std_dev_return, num_simulations)
        mc_var_return = -np.percentile(simulated_returns, alpha * 100)
        
        var_results[asset] = {
            'Delta-Normal VaR (%)': delta_normal_var_return * 100,
            'Simulaci√≥n Hist√≥rica VaR (%)': historical_var_return * 100,
            'Simulaci√≥n Monte Carlo VaR (%)': mc_var_return * 100
        }
    
    return pd.DataFrame(var_results).T

# --- Funciones de Backtesting (Kupiec y L√≥pez) ---

def kupiec_test(exceptions, total_observations, alpha):
    """Prueba de Cobertura No Condicional (LRuc)."""
    
    N = total_observations
    x = exceptions
    p = alpha
    
    E = N * p
    
    # Calcular LRuc
    if x == 0:
        LRuc = -2 * (N * np.log(1 - p) - (N - x) * np.log(1 - E / N))
    elif x == N:
        LRuc = -2 * (x * np.log(p) - x * np.log(x / N))
    elif E == 0 or E == N:
        LRuc = 0 
    else:
        with np.errstate(divide='ignore', invalid='ignore'):
            LRuc = -2 * (x * np.log(p) + (N - x) * np.log(1 - p) - x * np.log(x / N) - (N - x) * np.log(1 - x / N))
    
    # p-valor de chi-cuadrado con 1 g.d.l.
    p_value = 1 - chi2.cdf(LRuc, 1)
    
    return LRuc, p_value, E

def lopez_loss_function(returns, var_values):
    """Funci√≥n de P√©rdida Binaria de L√≥pez simplificada (Loss Function)."""
    
    # Indicador de excepci√≥n (1 si p√©rdida > VaR, 0 en otro caso)
    exception_indicator = (-returns > var_values).astype(int)
    
    # La p√©rdida es simplemente el n√∫mero total de excepciones (violaciones)
    total_loss = np.sum(exception_indicator)
    
    return total_loss

def perform_backtesting(df_returns, var_df, confidence_level):
    """Calcula las excepciones, realiza la prueba de Kupiec y la funci√≥n de p√©rdida de L√≥pez."""
    
    alpha = 1 - confidence_level
    total_obs = len(df_returns)
    all_results = []
    
    method_mapping = {
        'Delta-Normal VaR': 'Delta-Normal VaR (%)',
        'Simulaci√≥n Hist√≥rica VaR': 'Simulaci√≥n Hist√≥rica VaR (%)',
        'Simulaci√≥n Monte Carlo VaR': 'Simulaci√≥n Monte Carlo VaR (%)'
    }

    for asset in df_returns.columns:
        returns = df_returns[asset].values
        
        for method_name, col_name in method_mapping.items():
            var_value_pct = var_df.loc[asset, col_name]
            var_values = np.array([var_value_pct / 100] * total_obs) 
            
            # 1. Cobertura No Condicional (Kupiec)
            exceptions = np.sum(-returns > var_values)
            LRuc, p_value_uc, expected_x = kupiec_test(exceptions, total_obs, alpha)
            
            # 2. Funci√≥n de P√©rdida de L√≥pez
            total_loss = lopez_loss_function(returns, var_values) 

            def get_kupiec_result(p_val, level=0.01):
                return 'Pas√≥' if p_val >= level else 'Fall√≥'
            
            all_results.append({
                'Activo': asset,
                'M√©todo VaR': method_name,
                'x Observadas': exceptions,
                'x Esperadas': f'{expected_x:.2f}',
                
                'Kupiec (LRuc)': f'{LRuc:.3f}',
                'p-valor LRuc': f'{p_value_uc:.4f}',
                'Resultado Kupiec': get_kupiec_result(p_value_uc),
                
                # Reemplazo de Christoffersen por L√≥pez
                'L√≥pez (Loss)': total_loss,
                'Ranking L√≥pez (1=Mejor)': 0 # Placeholder, el ranking se har√° despu√©s
            })
            
    # Calcular el ranking de L√≥pez (menor p√©rdida total es mejor)
    results_df = pd.DataFrame(all_results)
    
    # Asignar ranking por activo: 1 al menor valor de 'L√≥pez (Loss)'
    results_df['Ranking L√≥pez (1=Mejor)'] = results_df.groupby('Activo')['L√≥pez (Loss)'].rank(method='min').astype(int)
    
    return results_df

# --- Funciones de Presentaci√≥n por Secci√≥n ---

def section_introduction(df_prices, df_returns):
    st.header("üéØ 1. Introducci√≥n y Metodolog√≠a")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Objetivo Principal")
        st.markdown(
            """
            <p style='font-size:1.5em; line-height:1.6;'>
            Analizar y <b>comparar el comportamiento del Valor en Riesgo (VaR)</b> estimado por tres metodolog√≠as clave 
            (Delta-Normal, Simulaci√≥n Hist√≥rica y Monte Carlo) en un portafolio simulado de activos bancarios, 
            validando su precisi√≥n mediante <b>pruebas de Backtesting</b>.
            </p>
            """, 
            unsafe_allow_html=True
        )

    with col2:
        st.subheader("Metodolog√≠as de Riesgo")
        st.markdown(
            """
            <p style='font-size:1.5em; line-height:1.6;'>
            1. <b>VaR Delta-Normal (Param√©trico):</b> Asume rendimientos normales. <br>
            2. <b>VaR Simulaci√≥n Hist√≥rica (No Param√©trico):</b> Usa cuantiles de la historia real. <br>
            3. <b>VaR Simulaci√≥n Monte Carlo (Mixto):</b> Simula caminos de precios (asumiendo Movimiento Browniano Geom√©trico). <br>
            4. <b>Backtesting (Kupiec & L√≥pez):</b> Valida la exactitud de la cobertura (Kupiec) y la penaliza por las violaciones (L√≥pez).
            </p>
            """, 
            unsafe_allow_html=True
        )

def section_eda(df_prices, df_returns, stats_df):
    st.header("üìä 2. An√°lisis Exploratorio de Datos (EDA)")
    
    st.subheader("2.1. Series de Precios Homogeneizados (USD)")
    
    fig_prices, ax_prices = plt.subplots(figsize=(10, 4))
    for column in df_prices.columns:
        ax_prices.plot(df_prices.index, df_prices[column], label=column)
    ax_prices.set_title('Precios de Cierre Diarios en USD', fontsize=16)
    ax_prices.set_xlabel('Fecha', fontsize=12)
    ax_prices.set_ylabel('Precio (USD)', fontsize=12)
    ax_prices.legend(loc='upper left', fontsize=8, ncol=2)
    ax_prices.grid(True, alpha=0.5)
    st.pyplot(fig_prices)

    st.subheader("2.2. Estad√≠sticas Descriptivas y Normalidad (Rendimientos)")
    st.dataframe(stats_df)
    
    st.markdown(
        """
        <p style='font-size:1.3em; line-height:1.5;'>
        <b>An√°lisis de Normalidad (Prueba de Jarque-Bera):</b> El p-valor de JB es significativamente <b>menor a 0.05</b> para todos los activos, lo que <b>rechaza la hip√≥tesis de normalidad</b>. 
        Esto indica la presencia de <b>colas pesadas</b> y <b>asimetr√≠a</b>, confirmando que el uso del VaR Delta-Normal puede ser inadecuado.
        </p>
        """,
        unsafe_allow_html=True
    )
    
    st.subheader("2.3. Distribuci√≥n de Rendimientos Diarios y QQ-Plots")
    
    selected_asset = st.selectbox("Seleccionar Activo para Gr√°ficos:", df_returns.columns)

    col_hist, col_qq = st.columns(2)
    
    with col_hist:
        # Histograma de Rendimientos
        fig_hist, ax_hist = plt.subplots(figsize=(6, 4))
        sns.histplot(df_returns[selected_asset], kde=True, bins=30, ax=ax_hist, color='skyblue')
        ax_hist.set_title(f'Distribuci√≥n de Rendimientos Diarios: {selected_asset}')
        ax_hist.set_xlabel('Rendimiento')
        ax_hist.set_ylabel('Frecuencia')
        st.pyplot(fig_hist)
        
    with col_qq:
        # QQ-Plot
        fig_qq, ax_qq = plt.subplots(figsize=(6, 4))
        sm.qqplot(df_returns[selected_asset].dropna(), line='s', ax=ax_qq)
        ax_qq.set_title(f'QQ-Plot (Normalidad): {selected_asset}')
        st.pyplot(fig_qq)
        

def section_var_estimation(var_results_df, confidence_level):
    st.header("üí∞ 3. Estimaci√≥n del Valor en Riesgo (VaR)")
    
    st.subheader(f"VaR Diario al {confidence_level:.3%} de Confianza")
    
    styled_var_df = var_results_df.copy()
    for col in styled_var_df.columns:
        styled_var_df[col] = (var_results_df[col]).apply(lambda x: f'{x:.4f}%') 
        
    st.dataframe(styled_var_df)

    st.markdown(
        """
        <p style='font-size:1.3em; line-height:1.5;'>
        <b>Observaciones Preliminares:</b>
        <ul>
            <li>Los modelos de VaR reflejan la <b>volatilidad</b> y las <b>propiedades de las colas</b> de los rendimientos.</li>
            <li>Una mayor desviaci√≥n de la normalidad (activos colombianos) resulta en una mayor dispersi√≥n entre el VaR Param√©trico y el VaR No Param√©trico.</li>
        </ul>
        </p>
        """,
        unsafe_allow_html=True
    )

# --- SECCI√ìN: 4. Estado del Arte de Pruebas ---
def section_state_of_the_art():
    st.header("üìö 4. Estado del Arte de las Pruebas de Backtesting")
    st.markdown("""
    El backtesting es un componente regulatorio y de gesti√≥n de riesgo esencial, evolucionando desde pruebas binarias hasta m√©tricas de funci√≥n de p√©rdida.

    ### 4.1. El Legado de Kupiec (LRuc)
    La prueba de **Raz√≥n de Verosimilitud No Condicional ($LR_{uc}$)**, propuesta por **Paul H. Kupiec (1995)**, es la piedra angular del backtesting. Su relevancia radica en:
    * **Simplicidad:** Se enfoca puramente en el **n√∫mero total de violaciones** ($x$) observadas.
    * **Regulatorio:** Es un requisito fundamental bajo los Acuerdos de Basilea para validar la precisi√≥n de los modelos VaR.
    * **Limitaci√≥n:** Ignora si las violaciones est√°n agrupadas en el tiempo (**clusterizaci√≥n**), lo que puede subestimar el riesgo sist√©mico o la inestabilidad del modelo. Esto condujo al desarrollo de pruebas condicionales como la de Christoffersen (reemplazada aqu√≠ por L√≥pez).

    ### 4.2. La Evoluci√≥n con las Funciones de P√©rdida (L√≥pez)
    Las pruebas basadas en **Funciones de P√©rdida (Loss Functions)**, popularizadas por **Jos√© A. L√≥pez (1998)**, representan una evoluci√≥n cualitativa.
    * **Enfoque:** En lugar de solo verificar la *frecuencia* (como Kupiec), estas pruebas eval√∫an la *gravedad* de los fallos, penalizando no solo la ocurrencia de una violaci√≥n sino tambi√©n la **magnitud** por la que la p√©rdida excedi√≥ el VaR (aunque en nuestra implementaci√≥n simplificada solo penalizamos la ocurrencia).
    * **Ventaja:** Ofrecen una medida **m√°s informativa y continua** del rendimiento del modelo, permitiendo al gestor de riesgo clasificar (rankear) los modelos y elegir el que minimice el "costo" o "p√©rdida" total, una perspectiva m√°s alineada con la toma de decisiones econ√≥micas.
    """)

def section_backtesting_explanation():
    st.header("üîç 5. Explicaci√≥n de las Pruebas de Backtesting")
    st.markdown("""
El Backtesting es un proceso crucial que eval√∫a la precisi√≥n y la calidad de un modelo de Valor en Riesgo (VaR) comparando las p√©rdidas reales con las predicciones del modelo.

### 5.1. Prueba de Cobertura No Condicional (Kupiec)
* Prop√≥sito: Es una prueba estad√≠stica que verifica si el n√∫mero de violaciones (d√≠as en que la p√©rdida real excede el VaR) observadas durante el per√≠odo de prueba es estad√≠sticamente igual al n√∫mero de violaciones esperadas por el modelo, dado el nivel de confianza (alpha).
* M√©trica: Utiliza una raz√≥n de verosimilitud (LRuc).
* Resultado: Si el modelo genera demasiadas o muy pocas violaciones, la prueba se rechaza ("Fall√≥"), indicando que el modelo es inexacto (subestima o sobrestima el riesgo).

### 5.2. Prueba de P√©rdida de Funci√≥n (L√≥pez)
* Prop√≥sito: Es una prueba de p√©rdida que asigna una puntuaci√≥n num√©rica o "coste" a la calidad del modelo. Permite clasificar los modelos por su rendimiento.
* M√©trica: Se implementa una Funci√≥n de P√©rdida Binaria simplificada, donde cada violaci√≥n suma una unidad a la p√©rdida total del modelo.
* Resultado: El modelo con la menor Puntuaci√≥n de P√©rdida (Loss) para un activo es considerado el m√°s preciso en esa dimensi√≥n y obtiene el Ranking 1.
""")


def section_backtesting(backtest_df):
    st.header("‚úÖ 6. Pruebas de Backtesting (Kupiec y L√≥pez)") 
    
    st.markdown("""
El backtesting eval√∫a la precisi√≥n del modelo en la pr√°ctica.

* Kupiec (LRuc): Prueba si el n√∫mero de fallos es igual al esperado (alpha).
* L√≥pez (Loss Function): Asigna una p√©rdida por cada violaci√≥n del VaR. Un menor valor de p√©rdida total indica un mejor modelo.
""")

    st.subheader("6.1. Resumen de Pruebas de Cobertura y Precisi√≥n")
    
    # Columnas actualizadas
    comparison_cols = ['Activo', 'M√©todo VaR', 'x Observadas', 'x Esperadas', 
                       'p-valor LRuc', 'Resultado Kupiec', 
                       'L√≥pez (Loss)', 'Ranking L√≥pez (1=Mejor)']
                       
    comparison_df = backtest_df[comparison_cols]
    
    # Aplicar formato condicional al DataFrame para presentaci√≥n
    def color_result(val):
        color = 'lightcoral' if val == 'Fall√≥' else ('lightgreen' if val == 'Pas√≥' else '')
        return f'background-color: {color}'

    st.dataframe(comparison_df.style.applymap(color_result, subset=['Resultado Kupiec']))
    
    
def section_findings(backtest_df, stats_df):
    st.header("üåü 7. Conclusiones y Hallazgos Principales")
    st.subheader("7.1. No Normalidad y Modelado del Riesgo")
    st.markdown(
        """
        <div style='font-size:1.5em; line-height:1.7;'>
        <p>El an√°lisis de la distribuci√≥n de rendimientos mediante la <b>prueba de Jarque-Bera (JB)</b> confirm√≥ la presencia de <b>asimetr√≠a</b> (sesgo) y <b>exceso de curtosis</b> (colas pesadas) en todos los activos (p-valor JB < 0.05).</p>
        <p>Este hallazgo es fundamental: <b>la suposici√≥n de normalidad es rechazada</b>, invalidando la base te√≥rica del VaR Delta-Normal para los activos estudiados.</p>
        </div>
        """,
        unsafe_allow_html=True
    )
    
    st.subheader("7.2. Desempe√±o del VaR por Metodolog√≠a")
    
    st.markdown("### A. VaR Delta-Normal (Param√©trico)")
    st.markdown(
        """
        <div style='font-size:1.3em; line-height:1.5;'>
        <ul>
            <li><b>Estimaci√≥n:</b> Produjo los valores de VaR m√°s <b>bajos</b>, indicando una subestimaci√≥n del riesgo, particularmente para los activos con alta no-normalidad.</li>
            <li><b>Backtesting (Kupiec):</b> <b>Fall√≥</b> la prueba de <b>Cobertura No Condicional (LRuc)</b> en la mayor√≠a de los casos. El n√∫mero de <b>excepciones observadas super√≥ significativamente al n√∫mero esperado</b>, confirmando que el modelo es inexacto y subestima la p√©rdida m√°xima potencial.</li>
            <li><b>Backtesting (L√≥pez):</b> Dado el alto n√∫mero de violaciones, el VaR Delta-Normal obtendr√° una <b>puntuaci√≥n de p√©rdida alta</b> (o un bajo ranking).</li>
        </ul>
        </div>
        """,
        unsafe_allow_html=True
    )

    st.markdown("### B. VaR de Simulaci√≥n Hist√≥rica (No Param√©trico)")
    st.markdown(
        """
        <div style='font-size:1.3em; line-height:1.5;'>
        <ul>
            <li><b>Estimaci√≥n:</b> Produjo valores de VaR m√°s <b>conservadores</b> (altos), ya que captura directamente los eventos de mercado extremos (p√©rdidas hist√≥ricas).</li>
            <li><b>Backtesting (Kupiec):</b> Generalmente logra <b>pasar la prueba de Cobertura (LRuc)</b>, indicando un n√∫mero de fallos consistente con el nivel de confianza.</li>
            <li><b>Backtesting (L√≥pez):</b> Este modelo tender√° a tener la <b>p√©rdida total m√°s baja</b> (o el ranking 1), ya que es m√°s robusto a las colas pesadas.</li>
        </ul>
        </div>
        """,
        unsafe_allow_html=True
    )

    st.markdown("### C. VaR de Simulaci√≥n Monte Carlo (Mixto)")
    st.markdown(
        """
        <div style='font-size:1.3em; line-height:1.5;'>
        <ul>
            <li><b>Estimaci√≥n:</b> Al simular los rendimientos bajo la <b>suposici√≥n de normalidad</b>, sus resultados fueron muy similares al VaR Delta-Normal, heredando sus debilidades.</li>
            <li><b>Backtesting (Kupiec y L√≥pez):</b> Tiende a <b>fallar Kupiec</b> y a obtener una **puntuaci√≥n de p√©rdida alta** en la prueba de L√≥pez, similar al Delta-Normal.</li>
            <li><b>Implicaci√≥n:</b> Para que Monte Carlo sea preciso en la pr√°ctica, requerir√≠a la calibraci√≥n y simulaci√≥n de distribuciones que modelen correctamente las colas pesadas (e.g., distribuci√≥n T de Student o modelos GARCH).</li>
        </ul>
        </div>
        """,
        unsafe_allow_html=True
    )
    
    st.subheader("7.3. Recomendaci√≥n Final")
    st.markdown(
        """
        <div style='font-size:1.5em; line-height:1.7;'>
        <p>Debido al rechazo de la normalidad, al desempe√±o de <b>Kupiec</b> y a la mejor <b>puntuaci√≥n de p√©rdida (L√≥pez)</b>, se recomienda utilizar el <b>Valor en Riesgo de Simulaci√≥n Hist√≥rica</b> como la m√©trica principal para la medici√≥n del riesgo de mercado en este portafolio.</p>
        <p>El VaR param√©trico (Delta-Normal) debe ser descartado, ya que su subestimaci√≥n del riesgo podr√≠a llevar a decisiones financieras deficientes.</p>
        </div>
        """,
        unsafe_allow_html=True
    )

# --- SECCI√ìN: 8. Referencias ---
def section_references():
    st.header("üìñ 8. Referencias del Estado del Arte")
    st.markdown("""
    * **Kupiec, P. H. (1995).** *Techniques for verifying the accuracy of risk measurement models.* The Journal of Derivatives, 3(2), 73-84.
    * **L√≥pez, J. A. (1998).** *Methods for evaluating value-at-risk estimates.* Economic Policy Review, Federal Reserve Bank of New York, 4(3), 119-144.
    * **Basilea (2019).** *Standards for calculating capital requirements for market risk.* (Documentos del Comit√© de Supervisi√≥n Bancaria de Basilea que regulan el uso del backtesting en la banca global).
    * √Ålvarez Ruiz, M. C., & Parra Oquendo, L. Y. (2024). *C√°lculo del valor en riesgo (VaR) mediante el uso de diferentes metodolog√≠as para dos portafolios del mercado bancario colombiano y americano.* Efectivo, (39), 21‚Äì38. Instituto Tecnol√≥gico Metropolitano.
    * Caicedo, H. S. O., & Casta√±eda, A. F. V. (2022). *Ranking del riesgo de mercado de los bancos que cotizan en la Bolsa de Valores de Colombia (BVC) utilizando metodolog√≠as VaR para el periodo de enero de 2020 a marzo de 2022.* [Trabajo de grado, Escuela Colombiana de Ingenier√≠a Julio Garavito]. Repositorio Institucional Escuelaing. [https://repositorio.escuelaing.edu.co/entities/publication/5dc961e5-3a8f-403f-8819-6f402d3672a9](https://repositorio.escuelaing.edu.co/entities/publication/5dc961e5-3a8f-403f-8819-6f402d3672a9)
    * Pineda, M. S. G., Agudelo, A. A. A., Rojas, R. A. M., & Duque, P. L. H. (2021). *Valor en riesgo y simulaci√≥n: una revisi√≥n sistem√°tica.* Econ√≥micas CUC, 43(1), 57‚Äì82. [https://revistascientificas.cuc.edu.co/economicascuc/article/view/3093](https://revistascientificas.cuc.edu.co/economicascuc/article/view/3093)
    * Sener, E., Baronyan, S., & Meng√ºt√ºrk, L. A. (2012). *Ranking the predictive performances of value-at-risk estimation methods.* International Journal of Forecasting, 28(4), 849‚Äì873. [https://www.sciencedirect.com/science/article/abs/pii/S0169207012000027?via%3Dihub](https://www.sciencedirect.com/science/article/abs/pii/S0169207012000027?via%3Dihub)
    * Trejo, B. R. B., & Gallegos, A. D. (2021). *Estimaci√≥n del riesgo de mercado utilizando el VaR y la beta del CAPM.* Revista Mexicana de Econom√≠a y Finanzas Nueva √âpoca, 16(2), 1‚Äì26. [https://www.remef.org.mx/index.php/remef/article/view/589](https://www.remef.org.mx/index.php/remef/article/view/589)
    """)
# --- FIN SECCI√ìN ---
    
# --- L√≥gica Principal de la Aplicaci√≥n ---

def main():
    st.title("üìä An√°lisis de Riesgo de Mercado: Comparaci√≥n de Metodolog√≠as VaR")
    
    # --- 1. Sidebar para Par√°metros y Navegaci√≥n ---
    with st.sidebar:
        st.header("Men√∫ de Navegaci√≥n")
        # LISTA DE NAVEGACI√ìN ACTUALIZADA
        page = st.radio(
            "Seleccione la Secci√≥n:",
            ["1. Introducci√≥n y Metodolog√≠a", 
             "2. An√°lisis Exploratorio (EDA)", 
             "3. Estimaci√≥n del VaR", 
             "4. Estado del Arte de Pruebas",
             "5. Explicaci√≥n de Pruebas", 
             "6. Backtesting",
             "7. Conclusiones y Hallazgos Principales",
             "8. Referencias"]
        )
        
        st.markdown("---")
        st.header("Par√°metros del Modelo")
        confidence_level = st.slider(
            'Nivel de Confianza (1 - alpha)',
            min_value=0.90,
            max_value=0.999,
            value=0.99,
            step=0.001,
            format="%.3f"
        )
        alpha = 1 - confidence_level
        st.info(f"Probabilidad de Excepci√≥n (alpha): <b>{alpha:.3%}</b>")
        st.markdown(f"<b>Observaciones:</b> {pd.to_datetime(START_DATE).date()} a {pd.to_datetime(END_DATE).date()}", unsafe_allow_html=True)

    # --- 2. Carga y Preparaci√≥n de Datos (Cach√©) ---
    combined_usd_df, daily_returns_df = load_and_prepare_data(COMPANIES, START_DATE, END_DATE)
    
    if combined_usd_df.empty:
        st.error("Error al cargar datos. Verifique los tickers y el rango de fechas en el c√≥digo fuente.")
        st.stop()
    
    # C√°lculos principales
    stats_df = calculate_descriptive_statistics(combined_usd_df, daily_returns_df)
    var_results_df = calculate_var(daily_returns_df, confidence_level, NUM_SIMULATIONS)
    backtest_df = perform_backtesting(daily_returns_df, var_results_df, confidence_level)
        
    # --- 3. Renderizar Secci√≥n Seleccionada (L√≥gica de Renderizado Actualizada) ---
    st.markdown("---")
    if page == "1. Introducci√≥n y Metodolog√≠a":
        section_introduction(combined_usd_df, daily_returns_df)
    elif page == "2. An√°lisis Exploratorio (EDA)":
        section_eda(combined_usd_df, daily_returns_df, stats_df)
    elif page == "3. Estimaci√≥n del VaR":
        section_var_estimation(var_results_df, confidence_level)
    elif page == "4. Estado del Arte de Pruebas":
        section_state_of_the_art()
    elif page == "5. Explicaci√≥n de Pruebas":
        section_backtesting_explanation()
    elif page == "6. Backtesting":
        section_backtesting(backtest_df)
    elif page == "7. Conclusiones y Hallazgos Principales":
        section_findings(backtest_df, stats_df)
    elif page == "8. Referencias":
        section_references()


if __name__ == '__main__':
    main()